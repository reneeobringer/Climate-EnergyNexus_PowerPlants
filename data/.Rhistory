knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Teaching/data/EME597/FiveCitiesPMData')
library(neuralnet)
library(keras)
library(ISLR2)
xdata <- data.matrix(NYSE[, c("DJ_return", "log_volume","log_volatility")] )
istrain <- NYSE[, "train"]
xdata <- scale(xdata)
# function for time series lags
lagm <- function(x, k = 1) {
n <- nrow(x)
pad <- matrix(NA, k, ncol(x))
rbind(pad, x[1:(n - k), ])
}
# function for time series lags
lagm <- function(x, k = 1) {
n <- nrow(x)
pad <- matrix(NA, k, ncol(x))
rbind(pad, x[1:(n - k), ])
}
arframe <- data.frame(log_volume = xdata[, "log_volume"],
L1 = lagm(xdata, 1), L2 = lagm(xdata, 2),
L3 = lagm(xdata, 3), L4 = lagm(xdata, 4),
L5 = lagm(xdata, 5))
rnn_mod <- keras_model_sequential() %>%
layer_simple_rnn(units = 12, input_shape = list(5, 3), dropout = 0.1, recurrent_dropout = 0.1) %>%
layer_dense(units = 1)
rnn_mod %>% compile(optimizer = optimizer_rmsprop(), loss = "mse")
rnn_modfit <- rnn_mod %>% fit(xrnn[istrain,, ], arframe[istrain, "log_volume"], batch_size = 64, epochs = 200,
validation_data = list(xrnn[!istrain,, ], arframe[!istrain, "log_volume"]) )
# reorganize data for RNN
n <- nrow(arframe)
xrnn <- data.matrix(arframe[, -1]) > xrnn <- array(xrnn, c(n, 3, 5))
# reorganize data for RNN
n <- nrow(arframe)
xrnn <- data.matrix(arframe[, -1])
xrnn <- array(xrnn, c(n, 3, 5))
xrnn <- xrnn[,, 5:1]
xrnn <- aperm(xrnn, c(1, 3, 2))
rnn_modfit <- rnn_mod %>% fit(xrnn[istrain,, ], arframe[istrain, "log_volume"], batch_size = 64, epochs = 200,
validation_data = list(xrnn[!istrain,, ], arframe[!istrain, "log_volume"]) )
rnn_modfit <- rnn_mod %>% fit(xrnn[istrain,, ], arframe[istrain, "log_volume"], batch_size = 64, epochs = 10,
validation_data = list(xrnn[!istrain,, ], arframe[!istrain, "log_volume"]) )
ypred <- predict(rnn_mod, xrnn[!istrain,, ])
1 - mean((ypred - arframe[!istrain, "log_volume"])^2) / V0
View(ypred)
rnn_modfit <- rnn_mod %>% fit(xrnn[istrain,, ], arframe[istrain, "log_volume"], batch_size = 64, epochs = 10,
validation_data = list(xrnn[!istrain,, ], arframe[!istrain, "log_volume"]) )
ypred <- predict(rnn_mod, xrnn[!istrain,, ])
1 - mean((ypred - arframe[!istrain, "log_volume"])^2) / V1
rnn_modfit <- rnn_mod %>% fit(xrnn[istrain,, ], arframe[istrain, "log_volume"], batch_size = 64, epochs = 10,
validation_data = list(xrnn[!istrain,, ], arframe[!istrain, "log_volume"]) )
ypred <- predict(rnn_mod, xrnn[!istrain,, ])
plot(rnn_modfit)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Teaching/data/EME597')
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
View(solarpotential)
View(solarpotential)
names(solarpotential)
View(solarpotential)
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
solarpotential <- na.omit(solarpotential)
solarpotential <- solarpotential[,-c(1:3,6,11)]
View(solarpotential)
names(solarpotential)
View(solarpotential)
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
solarpotential <- solarpotential[,-c(1:3,6,11)]
names(solarpotential) <- c('Population','Area','HDI','GDP','GHI','PVcap','RuralElectric','Consumption')
solarpotential <- as.numeric(solarpotential)
View(solarpotential)
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
solarpotential <- solarpotential[,-c(1:3,6,11)]
names(solarpotential) <- c('Population','Area','HDI','GDP','GHI','PVcap','RuralElectric','Consumption')
solarpotential <- lapply(solarpotential, as.numeric)
View(solarpotential)
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
solarpotential <- solarpotential[,-c(1:3,6,11)]
names(solarpotential) <- c('Population','Area','HDI','GDP','GHI','PVcap','RuralElectric','Consumption')
solarpotential <- sapply(solarpotential, as.numeric)
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
solarpotential <- solarpotential[,-c(1:3,6,11)]
names(solarpotential) <- c('Population','Area','HDI','GDP','GHI','PVcap','RuralElectric','Consumption')
solarpotential[] <- sapply(solarpotential, as.numeric)
View(solarpotential)
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
solarpotential <- solarpotential[,-c(1:3,6,11)]
names(solarpotential) <- c('Population','Area','HDI','GDP','GHI','PVcap','RuralElectric','Consumption')
solarpotential[] <- sapply(solarpotential, as.numeric)
solarpotential <- na.omit(solarpotential)
View(solarpotential)
```{r}
library(readxl)
solarpotential <- read_excel('worldsolarpotential.xlsx')
solarpotential <- solarpotential[,-c(1:3,6,11)]
names(solarpotential) <- c('Population','Area','HDI','GDP','GHI','PVcap','RuralElectric','Consumption')
solarpotential[] <- sapply(solarpotential, as.numeric)
solarpotential <- na.omit(solarpotential)
library(e1071)
library(ggplot2)
# Split into training and test sets
set.seed(1234)
# Split into training and test sets
set.seed(1234)
sample_rows <- sample(nrow(solarpotential), size = 0.8*nrow(solarpotential), replace = F)
trainingdata <- solarpotential[sample_rows,]
testdata <- solarpotential[-sample_rows,]
# fit the SVM
svm_mod <- svm(PVap ~ ., data = trainingdata)
# Split into training and test sets
set.seed(1234)
sample_rows <- sample(nrow(solarpotential), size = 0.8*nrow(solarpotential), replace = F)
trainingdata <- solarpotential[sample_rows,]
testdata <- solarpotential[-sample_rows,]
# fit the SVM
svm_mod <- svm(PVcap ~ ., data = trainingdata)
# predict using the test set
ypred <- predict(svm_mod, newdata = testdata) # predict with test set
print(paste('Test RMSE: ', sqrt(mean((testdata$PVcap - ypred)^2)),' MWp', sep = ''))
# create new dataframe for ggplot
plotdata <- data.frame(actual = testdata$PVcap, predicted = ypred)
# plot the actual vs. predicted values
ggplot(plotdata) + geom_point(aes(x = actual, y = predicted)) + geom_abline(slope = 1, intercept = 0, color = 'red') + ylab('Predicted PM2.5 (ug/m^3)') + xlab('Actual PM2.5 (ug/m^3)')
# create grid search for tuning
tuning <- tune(svm, PVcap ~ ., data = trainingdata, ranges = list(gamma = c(0.01, 0.1, 0.25), cost = c(4, 8, 16), degree = c(3,4,5)), kernel = 'polynomial')
# store best mode
tuned_svm_mod <- tuning$best.model
# predict using the test set
ypred <- predict(tuned_svm_mod, newdata = pmdata_new_test) # predict with test set
# create grid search for tuning
tuning <- tune(svm, PVcap ~ ., data = trainingdata, ranges = list(gamma = c(0.01, 0.1, 0.25), cost = c(4, 8, 16), degree = c(3,4,5)), kernel = 'polynomial')
# store best mode
tuned_svm_mod <- tuning$best.model
# predict using the test set
ypred <- predict(tuned_svm_mod, newdata = testdata) # predict with test set
print(paste('Test RMSE: ', sqrt(mean((testdata$PVcap - ypred)^2)),' MWp', sep = ''))
View(trainingdata)
# scale data
scaleddata <- scale(solarpotential)
pvscaled <- as.data.frame(scaleddata)
scalevalues <-  attr(scaleddata, 'scaled:scale')
centervalues <- attr(scaleddata, 'scaled:center')
# Split into training and test sets
set.seed(1234)
sample_rows <- sample(nrow(pvscaled), size = 0.8*nrow(pvscaled), replace = F)
pvnorm_train <- pvscaled[sample_rows,]
pvnorm_test <- pvscaled[-sample_rows,]
# set up model architecture
nn_mod <- keras_model_sequential() %>%
layer_dense(units = 30, activation = 'relu') %>%
layer_dense(units = 10, activation = 'relu') %>%
layer_dense(units = 25, activation = 'softmax') %>%
layer_dense(units = 1)
nn_mod %>% compile(optimizer = 'adam', loss = 'mse',metrics = list('mse', 'mae'))
# fit the model
data <- as.matrix(pvnorm_train[,-6])
labels <- as.matrix(pvnorm_train[,6])
val_data <- as.matrix(pvnorm_test[,-6])
val_labels <- as.matrix(pvnorm_test[,6])
modfit <- nn_mod %>% fit(data, labels, epochs = 100, validation_data = list(val_data, val_labels))
# prediction
ypred <- nn_mod %>% predict(val_data)
# un-scale the data
ypred <- ypred * scalevalues[1] + centervalues[1]
ytest <- pvnorm_test$PVcap * scalevalues[1] + centervalues[1]
print(paste('Test RMSE: ', sqrt(mean((ytest - ypred)^2)),' MWp', sep = ''))
# plots
plot(modfit)
ggplot() +
geom_point(aes(x = ytest, y = ypred)) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed')
ypred
pvnorm_test
val_labels
# scale data
scaleddata <- scale(solarpotential)
pvscaled <- as.data.frame(scaleddata)
scalevalues <-  attr(scaleddata, 'scaled:scale')
centervalues <- attr(scaleddata, 'scaled:center')
# Split into training and test sets
set.seed(1234)
sample_rows <- sample(nrow(pvscaled), size = 0.8*nrow(pvscaled), replace = F)
pvscale_train <- pvscaled[sample_rows,]
pvscale_test <- pvscaled[-sample_rows,]
# set up model architecture
nn_mod <- keras_model_sequential() %>%
layer_dense(units = 30, activation = 'relu') %>%
layer_dense(units = 10, activation = 'relu') %>%
layer_dense(units = 25, activation = 'softmax') %>%
layer_dense(units = 1)
nn_mod %>% compile(optimizer = 'adam', loss = 'mse',metrics = list('mse', 'mae'))
# fit the model
data <- as.matrix(pvscale_train[,-6])
labels <- as.matrix(pvscale_train[,6])
val_data <- as.matrix(pvscale_test[,-6])
val_labels <- as.matrix(pvscale_test[,6])
modfit <- nn_mod %>% fit(data, labels, epochs = 100, validation_data = list(val_data, val_labels))
# prediction
ypred <- nn_mod %>% predict(val_data)
# un-scale the data
ypredunscale <- ypred * scalevalues[1] + centervalues[1]
ytestunscale <- pvnorm_test$PVcap * scalevalues[1] + centervalues[1]
print(paste('Test RMSE: ', sqrt(mean((ytestunscale - ypredunscale)^2)),' MWp', sep = ''))
# plots
plot(modfit)
ggplot() +
geom_point(aes(x = ytestunscale, y = ypredunscale)) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed')
ypred
library(keras)
# scale data
scaleddata <- scale(solarpotential)
pvscaled <- as.data.frame(scaleddata)
scalevalues <-  attr(scaleddata, 'scaled:scale')
centervalues <- attr(scaleddata, 'scaled:center')
# Split into training and test sets
set.seed(1234)
sample_rows <- sample(nrow(pvscaled), size = 0.8*nrow(pvscaled), replace = F)
pvscale_train <- pvscaled[sample_rows,]
pvscale_test <- pvscaled[-sample_rows,]
# set up model architecture
nn_mod <- keras_model_sequential() %>%
layer_dense(units = 30, activation = 'relu') %>%
layer_dense(units = 10, activation = 'relu') %>%
layer_dense(units = 25, activation = 'softmax') %>%
layer_dense(units = 1)
nn_mod %>% compile(optimizer = 'adam', loss = 'mse',metrics = list('mae'))
# fit the model
data <- as.matrix(pvscale_train[,-6])
labels <- as.matrix(pvscale_train[,6])
val_data <- as.matrix(pvscale_test[,-6])
val_labels <- as.matrix(pvscale_test[,6])
modfit <- nn_mod %>% fit(data, labels, epochs = 100, validation_data = list(val_data, val_labels))
# prediction
ypred <- nn_mod %>% predict(val_data)
# un-scale the data
ypredunscale <- ypred * scalevalues[6] + centervalues[6]
ytestunscale <- pvnorm_test$PVcap * scalevalues[6] + centervalues[6]
print(paste('Test RMSE: ', sqrt(mean((ytestunscale - ypredunscale)^2)),' MWp', sep = ''))
# plots
plot(modfit)
ggplot() +
geom_point(aes(x = ytestunscale, y = ypredunscale)) +
geom_abline(slope = 1, intercept = 0, linetype = 'dashed')
# libraries
library(dplyr)
library(stringr)
library(tidyr)
library(reshape2)
library(ggplot2)
library(cowplot)
library(scales)
library(hydroGOF) # for NRMSE calculations
library(lubridate)
# directories
datadir <- '/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Research/2024_25/papers/RenewableEnergy/datapaper/datafiles'
figuredir <- '/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Research/2024_25/papers/RenewableEnergy/datapaper/figures'
# libraries
library(readxl)
########## LOAD DATA #################
precipdata <- read_excel(paste(datadir, '/acpcp.agg.2011.2022.xlsx'))
########## LOAD DATA #################
precipdata <- read_excel(paste(datadir, '/acpcp.agg.2011.2022.xlsx', sep = ''))
View(precipdata)
# NARR data
convectprecipdata <- read_excel(paste(datadir, '/acpcp.agg.2011.2022.xlsx', sep = ''))  # convective precipitation accumulation (kg/m^2)
temppdata <- read_excel(paste(datadir, '/air.agg.2011.2022.xlsx', sep = ''))            # air temperature (K)
albedodata <- read_excel(paste(datadir, '/albedo.agg.2011.2022.xlsx', sep = ''))        # albedo (%)
precipdata <- read_excel(paste(datadir, '/apcp.agg.2011.2022.xlsx', sep = ''))          # precipitation amount (kg/m^2)
dewpointdata <- read_excel(paste(datadir, '/dpt.agg.2011.2022.xlsx', sep = ''))         # dew point temperature (K)
pottempdata <- read_excel(paste(datadir, '/pottmp.agg.2011.2022.xlsx', sep = ''))       # potential temperature (K)
rhdata <- read_excel(paste(datadir, '/rhum.agg.2011.2022.xlsx', sep = ''))              # relative humidity (%)
cloudcoverdata <- read_excel(paste(datadir, '/tcdc.agg.2011.2022.xlsx', sep = ''))      # total cloud cover (%)
uwinddata <- read_excel(paste(datadir, '/uwnd.agg.2011.2022.xlsx', sep = ''))           # u-component of wind (m/s)
vwinddata <- read_excel(paste(datadir, '/vwnd.agg.2011.2022.xlsx', sep = ''))           # v-component of wind (m/s)
# EIA data
plantdata <- read_excel(paste(datadir, '/eia_master_df.xlsx', sep = ''))
View(albedodata)
# merge all NARR datasets
datasets <- list(convectprecipdata, temppdata, albedodata, precipdata, dewpointdata, pottempdata, rhdata, cloudcoverdata, uwinddata, vwinddata)
View(datasets)
library(purrr)
View(albedodata)
narrdata <- purrr::reduce(.x = datasets, merge, by = c('plant_code', 'year', 'month'), all = T)
View(narrdata)
# write to csv
write.csv(narrdata, 'allnardata.csv')
uwnd <- read.csv('uwnd.daily.2011.2022.csv')
# libraries
library(readxl)
library(data.table)
library(dtplyr)
library(dplyr)
# read back in wind speeds and convert to total wind speed
setwd('/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Research/data/NARR/powerplants')
uwnd <- read.csv('uwnd.daily.2011.2022.csv')
vwnd <- read.csv('vwnd.daily.2011.2022.csv')
wnd <- sqrt(uwnd$uwnd^2 + vwnd$vwnd^2)
wnd <- data.frame(uwnd[,1:7], wnd)
View(wnd)
write.csv(wnd, 'wnd.daily.2011.2022.csv')
variables <- c('acpcp', 'air', 'albedo', 'apcp', 'dpt', 'pottmp', 'rhum', 'tcdc', 'wnd')
filenames <- list.files(pattern ='*daily*', full.names = F)
filenames <- filenames[-c(9:10)] # remove uwnd/vwnd
for (i in 1:length(variables)) {
# read in data
data <- read.csv(filenames[i])
# convert to data.table for faster processing
data_DT <- data.table(data)
# aggregate to monthly values
if (variables[i] == 'acpcp' | variables[i] == 'apcp') {
monthlyvalues <- data_DT %>% group_by(plant_code, year, month) %>%
summarize(total = sum(get(variables[i])), min = min(get(variables[i])), max = max(get(variables[i])), avg = mean(get(variables[i]))) %>%
collect()
names(monthlyvalues[4:7]) <- c(paste(variables[i], '_total', sep = ''), paste(variables[i], '_min', sep = ''), paste(variables[i], '_max', sep = ''), paste(variables[i], '_avg', sep = ''))
} else {
monthlyvalues <- data_DT %>% group_by(plant_code, year, month) %>%
summarize(min = min(get(variables[i])), max = max(get(variables[i])), avg = mean(get(variables[i]))) %>%
collect()
names(monthlyvalues[4:6]) <- c(paste(variables[i], '_min', sep = ''), paste(variables[i], '_max', sep = ''), paste(variables[i], '_avg', sep = ''))
}
newfilename <- paste(variables[i], '.agg.2011.2022.csv', sep = '')
write.csv(monthlyvalues, newfilename)
}
rm(list=ls())
options(scipen = 999)
# libraries
library(readxl)
library(purrr)
library(dplyr)
library(lubridate)
library(rnaturalearth)
library(ggplot2)
library(sf)
library(cowplot)
# directories
maindir <- '/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Research/GitHub/public/Climate-EnergyNexus_PowerPlants'
datadir1 <- paste(maindir, '/data/NARRdata', sep = '')
datadir2 <- paste(maindir, '/data/EIAdata', sep = '')
# NARR data
convectprecipdata <- read.csv(paste(datadir1, '/acpcp.agg.2011.2022.csv', sep = ''))  # convective precipitation accumulation (kg/m^2)
temppdata <- read.csv(paste(datadir1, '/air.agg.2011.2022.csv', sep = ''))            # air temperature (K)
albedodata <- read.csv(paste(datadir1, '/albedo.agg.2011.2022.csv', sep = ''))        # albedo (%)
precipdata <- read.csv(paste(datadir1, '/apcp.agg.2011.2022.csv', sep = ''))          # precipitation amount (kg/m^2)
dewpointdata <- read.csv(paste(datadir1, '/dpt.agg.2011.2022.csv', sep = ''))         # dew point temperature (K)
pottempdata <- read.csv(paste(datadir1, '/pottmp.agg.2011.2022.csv', sep = ''))       # potential temperature (K)
rhdata <- read.csv(paste(datadir1, '/rhum.agg.2011.2022.csv', sep = ''))              # relative humidity (%)
cloudcoverdata <- read.csv(paste(datadir1, '/tcdc.agg.2011.2022.csv', sep = ''))      # total cloud cover (%)
winddata <- read.csv(paste(datadir1, '/wnd.agg.2011.2022.csv', sep = ''))             # wind speed (m/s)
# EIA data
plantdata <- read_excel(paste(datadir2, '/eia_master_df.xlsx', sep = ''))
# EIA data
plantdata <- read_excel(paste(datadir2, '/eia_combined.xlsx', sep = ''))
latlondata <- read_excel(paste(maindir, '/miscellaneousfiles/REF_LAT_LON.xlsx', sep = ''))
statedata <- read_excel(paste(maindir, '/miscellaneousfiles/state_plantIDs.xlsx', sep = ''))
# merge all NARR dataframes
datasets <- list(convectprecipdata, temppdata, albedodata, precipdata, dewpointdata, pottempdata, rhdata, cloudcoverdata, uwinddata, vwinddata)
# merge all NARR dataframes
datasets <- list(convectprecipdata, temppdata, albedodata, precipdata, dewpointdata, pottempdata, rhdata, cloudcoverdata, winddata)
narrdata <- purrr::reduce(.x = datasets, merge, by = c('plant_code', 'year', 'month'), all = T)
names(monthlyvalues[4:7])
rm(list=ls())
options(scipen = 999)
# libraries
library(readxl)
library(data.table)
library(dtplyr)
library(dplyr)
# load daily data
setwd('/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Research/data/NARR/powerplants')
variables <- c('acpcp', 'air', 'albedo', 'apcp', 'dpt', 'pottmp', 'rhum', 'tcdc', 'wnd')
filenames <- list.files(pattern ='*daily*', full.names = F)
filenames <- filenames[-c(9:10)] # remove uwnd/vwnd
i <- 1
# read in data
data <- read.csv(filenames[i])
# convert to data.table for faster processing
data_DT <- data.table(data)
monthlyvalues <- data_DT %>% group_by(plant_code, year, month) %>%
summarize(total = sum(get(variables[i])), min = min(get(variables[i])), max = max(get(variables[i])), avg = mean(get(variables[i]))) %>%
collect()
names(monthlyvalues[4:7]) <- c(paste(variables[i], '_total', sep = ''), paste(variables[i], '_min', sep = ''), paste(variables[i], '_max', sep = ''), paste(variables[i], '_avg', sep = ''))
View(monthlyvalues)
names(monthlyvalues[4:7])
c(paste(variables[i], '_total', sep = ''), paste(variables[i], '_min', sep = ''), paste(variables[i], '_max', sep = ''), paste(variables[i], '_avg', sep = ''))
names(monthlyvalues)[4:7] <- c(paste(variables[i], '_total', sep = ''), paste(variables[i], '_min', sep = ''), paste(variables[i], '_max', sep = ''), paste(variables[i], '_avg', sep = ''))
View(monthlyvalues)
for (i in 1:length(variables)) {
# read in data
data <- read.csv(filenames[i])
# convert to data.table for faster processing
data_DT <- data.table(data)
# aggregate to monthly values
if (variables[i] == 'acpcp' | variables[i] == 'apcp') {
monthlyvalues <- data_DT %>% group_by(plant_code, year, month) %>%
summarize(total = sum(get(variables[i])), min = min(get(variables[i])), max = max(get(variables[i])), avg = mean(get(variables[i]))) %>%
collect()
names(monthlyvalues)[4:7] <- c(paste(variables[i], '_total', sep = ''), paste(variables[i], '_min', sep = ''), paste(variables[i], '_max', sep = ''), paste(variables[i], '_avg', sep = ''))
} else {
monthlyvalues <- data_DT %>% group_by(plant_code, year, month) %>%
summarize(min = min(get(variables[i])), max = max(get(variables[i])), avg = mean(get(variables[i]))) %>%
collect()
names(monthlyvalues)[4:6] <- c(paste(variables[i], '_min', sep = ''), paste(variables[i], '_max', sep = ''), paste(variables[i], '_avg', sep = ''))
}
newfilename <- paste(variables[i], '.agg.2011.2022.csv', sep = '')
write.csv(monthlyvalues, newfilename)
}
rm(list=ls())
options(scipen = 999)
# libraries
library(readxl)
library(purrr)
library(dplyr)
library(lubridate)
library(rnaturalearth)
library(ggplot2)
library(sf)
library(cowplot)
# directories
maindir <- '/Users/rqo5125/Library/Mobile Documents/com~apple~CloudDocs/Documents/Research/GitHub/public/Climate-EnergyNexus_PowerPlants'
datadir1 <- paste(maindir, '/data/NARRdata', sep = '')
datadir2 <- paste(maindir, '/data/EIAdata', sep = '')
# NARR data
convectprecipdata <- read.csv(paste(datadir1, '/acpcp.agg.2011.2022.csv', sep = ''))  # convective precipitation accumulation (kg/m^2)
temppdata <- read.csv(paste(datadir1, '/air.agg.2011.2022.csv', sep = ''))            # air temperature (K)
albedodata <- read.csv(paste(datadir1, '/albedo.agg.2011.2022.csv', sep = ''))        # albedo (%)
precipdata <- read.csv(paste(datadir1, '/apcp.agg.2011.2022.csv', sep = ''))          # precipitation amount (kg/m^2)
dewpointdata <- read.csv(paste(datadir1, '/dpt.agg.2011.2022.csv', sep = ''))         # dew point temperature (K)
pottempdata <- read.csv(paste(datadir1, '/pottmp.agg.2011.2022.csv', sep = ''))       # potential temperature (K)
rhdata <- read.csv(paste(datadir1, '/rhum.agg.2011.2022.csv', sep = ''))              # relative humidity (%)
cloudcoverdata <- read.csv(paste(datadir1, '/tcdc.agg.2011.2022.csv', sep = ''))      # total cloud cover (%)
winddata <- read.csv(paste(datadir1, '/wnd.agg.2011.2022.csv', sep = ''))             # wind speed (m/s)
# EIA data
plantdata <- read_excel(paste(datadir2, '/eia_combined.xlsx', sep = ''))
latlondata <- read_excel(paste(maindir, '/miscellaneousfiles/REF_LAT_LON.xlsx', sep = ''))
statedata <- read_excel(paste(maindir, '/miscellaneousfiles/state_plantIDs.xlsx', sep = ''))
# merge all NARR dataframes
datasets <- list(convectprecipdata, temppdata, albedodata, precipdata, dewpointdata, pottempdata, rhdata, cloudcoverdata, winddata)
narrdata <- purrr::reduce(.x = datasets, merge, by = c('plant_code', 'year', 'month'), all = T)
View(narrdata)
convectprecipdata <- read.csv(paste(datadir1, '/acpcp.agg.2011.2022.csv', sep = ''))  # convective precipitation accumulation (kg/m^2)
temppdata <- read.csv(paste(datadir1, '/air.agg.2011.2022.csv', sep = ''))            # air temperature (K)
albedodata <- read.csv(paste(datadir1, '/albedo.agg.2011.2022.csv', sep = ''))        # albedo (%)
precipdata <- read.csv(paste(datadir1, '/apcp.agg.2011.2022.csv', sep = ''))          # precipitation amount (kg/m^2)
dewpointdata <- read.csv(paste(datadir1, '/dpt.agg.2011.2022.csv', sep = ''))         # dew point temperature (K)
pottempdata <- read.csv(paste(datadir1, '/pottmp.agg.2011.2022.csv', sep = ''))       # potential temperature (K)
rhdata <- read.csv(paste(datadir1, '/rhum.agg.2011.2022.csv', sep = ''))              # relative humidity (%)
cloudcoverdata <- read.csv(paste(datadir1, '/tcdc.agg.2011.2022.csv', sep = ''))      # total cloud cover (%)
winddata <- read.csv(paste(datadir1, '/wnd.agg.2011.2022.csv', sep = ''))             # wind speed (m/s)
# merge all NARR dataframes
datasets <- list(convectprecipdata, temppdata, albedodata, precipdata, dewpointdata, pottempdata, rhdata, cloudcoverdata, winddata)
narrdata <- purrr::reduce(.x = datasets, merge, by = c('plant_code', 'year', 'month'), all = T)
View(narrdata)
temppdata <- read.csv(paste(datadir1, '/air.agg.2011.2022.csv', sep = ''))            # air temperature (K)
# merge all NARR dataframes
datasets <- list(convectprecipdata, temppdata, albedodata, precipdata, dewpointdata, pottempdata, rhdata, cloudcoverdata, winddata)
narrdata <- purrr::reduce(.x = datasets, merge, by = c('plant_code', 'year', 'month'), all = T)
View(narrdata)
# write to csv
setwd(paste(maindir, '/data', sep = ''))
write.csv(narrdata, 'allnarrdata.csv')
